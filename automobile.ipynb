{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "automobile.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-IaWe4VQS0zA"
      ],
      "toc_visible": true,
      "mount_file_id": "1Omp_UahFEw97tZpFKLCldsb8WhWJ4igF",
      "authorship_tag": "ABX9TyPzypb6fnDcEuA8GPtCDI4q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alcidescoutinho/pytorch_knn-impute_automobile/blob/main/automobile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introdução dos dados"
      ],
      "metadata": {
        "id": "z_R4_Mz3V1th"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data set consists of three types of entities:\n",
        " \n",
        "(a) the specification of an auto in terms of various characteristics \n",
        "\n",
        "(b) its assigned insurance risk rating \n",
        "\n",
        "(c) its normalized losses in use as compared to other cars.  \n",
        "\n",
        "The second rating corresponds to the\n",
        "degree to which the auto is more risky than its price indicates.\n",
        "Cars are initially assigned a risk factor symbol associated with its\n",
        "price.   Then, if it is more risky (or less), this symbol is\n",
        "adjusted by moving it up (or down) the scale.  Actuarians call this\n",
        "process \"symboling\".  A value of +3 indicates that the auto is\n",
        "risky, -3 that it is probably pretty safe.\n",
        "\n",
        "\n",
        "The third factor is the relative average loss payment per insured\n",
        "  vehicle year.  This value is normalized for all autos within a\n",
        "  particular size classification (two-door small, station wagons,\n",
        "  sports/speciality, etc...), and represents the average loss per car\n",
        "  per year.\n",
        "\n"
      ],
      "metadata": {
        "id": "9fTW9VXBV3ec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Localização do arquivo: https://archive.ics.uci.edu/ml/datasets/Automobile\n",
        "\n",
        "Com base na explicação da introdução, esse modelo busca alcançar a seguinte lista de objetivos:\n",
        "1. Preencher os vazios utilizando o KNN impute\n",
        "2. Criar uma rede neural utilizando pytorch para a previsão da regressão.\n",
        "3. Fazer um comparativo dos dados previstos com os reais."
      ],
      "metadata": {
        "id": "7fPg8po4rzBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importação"
      ],
      "metadata": {
        "id": "2cUUziXjs_sl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgFAKIe7UJo3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = ['symboling', 'normalized-losses', 'make',\n",
        "           'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels',\n",
        "           'engine-location', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type', \n",
        "           'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke',\n",
        "           'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
        "strings_mod = []\n",
        "\n",
        "for i in strings:\n",
        "  ii = i.replace('-','_')\n",
        "  strings_mod.append(ii)\n",
        "strings = strings_mod\n",
        "\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Projetos Portfólio/Regressão/imports-85 (1).csv',\n",
        "                      names=strings,\n",
        "                      header=None, \n",
        "                      na_values='?')"
      ],
      "metadata": {
        "id": "PAzENyq2XhJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processamento de dados"
      ],
      "metadata": {
        "id": "n4zkViYTd0hn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processamento de dados \n",
        "\n",
        "1. Visualização dos Unicos das features de classificação.\n",
        "2. Eliminar dados descrepantes\n",
        "3. Preencher Vázios\n",
        "4. Obter dados estatísticos e visualização de correlações\n",
        "\n",
        "Previsão de dados\n",
        "\n",
        "- obs: - Como o que irei utilizar de previsão é a coluna *normalized-losses*, irei separar os dados vázios para fazer a previsão, enquanto testo o previsor pelo cross-val com os outros modelos. \n",
        "\n",
        "1. Padronização das features\n",
        "2. Seleção das melhores\n",
        "3. Aplicação do ML"
      ],
      "metadata": {
        "id": "C0Ry7rDaQsMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funções\n"
      ],
      "metadata": {
        "id": "V_oPRmPKd26q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Função que possíbilita verificar diversas características dos dados"
      ],
      "metadata": {
        "id": "EmKCtQuRtLim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tabela_resumo(df):\n",
        "  import plotly.express as px\n",
        "  figura = df.isnull().sum().sort_values(ascending=True)\n",
        "\n",
        "  print(f'\\n\\n               Dataset Shape: {df.shape}\\n\\n')\n",
        "  print(f'               Dataset Duplicated: {df.duplicated().sum()}\\n\\n')\n",
        "  summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n",
        "  summary = summary.reset_index()\n",
        "  summary['Name'] = summary['index']\n",
        "  summary = summary[['Name','dtypes']]\n",
        "  summary['Missing'] = df.isnull().sum().values\n",
        "  summary['Unique'] = df.nunique().values\n",
        "  l = []\n",
        "  r = []\n",
        "  for i in summary['Name']:\n",
        "      l.append(df[i].value_counts().index[0])\n",
        "      r.append(df[i].value_counts().values[0])\n",
        "  max, min, mean, std, median = [], [], [], [], []\n",
        "  for n,i in enumerate(summary['dtypes']):\n",
        "    if (i == 'float64') | (i == 'int64'):\n",
        "      min.append(round(df.iloc[:,n].min(),3))\n",
        "      max.append(round(df.iloc[:,n].max(),3))\n",
        "      mean.append(round(df.iloc[:,n].mean(),3))\n",
        "      std.append(round(df.iloc[:,n].std(),3))\n",
        "      median.append(round(df.iloc[:,n].median(),3))\n",
        "    else:\n",
        "      min.append(f'class : {i}')\n",
        "      max.append(f'class : {i}')\n",
        "      mean.append(f'class : {i}')\n",
        "      std.append(f'class : {i}')\n",
        "      median.append(f'class : {i}')\n",
        "  summary['max'] = max\n",
        "  summary['min'] = min\n",
        "  summary['mean'] = mean\n",
        "  summary['std'] = std\n",
        "  summary['median'] = median\n",
        "\n",
        "  summary['Most repeated'] = l\n",
        "  summary['Repeated counts'] = r\n",
        "  summary['First Value'] = df.loc[0].values\n",
        "  summary['Second Value'] = df.loc[1].values\n",
        "\n",
        "  if df.isnull().sum().sum() > 0:\n",
        "    fig = px.bar(figura[figura>0], \n",
        "                orientation='h', \n",
        "                text_auto='.0f', \n",
        "                color=figura[figura>0].index,\n",
        "                color_discrete_sequence = px.colors.qualitative.Set2)\n",
        "    fig.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
        "\n",
        "    fig.show()\n",
        "  return summary"
      ],
      "metadata": {
        "id": "0vIzs9Z9d2bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Se a quantidade de unicos for maior do que 75%, considero esse dados como float,\n",
        "caso contrario, será considerado um dado classificável.\n",
        "\n",
        "\"\"\"\n",
        "def unicos(df):\n",
        "  qual = list()\n",
        "  for i in df:\n",
        "    if (len(df[i].unique()) / len(df)) < 0.75:\n",
        "      print(f'\\nModelo: {i} \\n   -> {df[i].unique()}')\n",
        "    else:\n",
        "      qual.append(i)\n",
        "  print(f'Dados quantitativos : {qual}')\n",
        "  return qual"
      ],
      "metadata": {
        "id": "PyK4A9mmTL9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN Impute\n",
        "Com a análise de dados, possível verificar que todas as linhas estão ok e 7 features tem dados faltantes.\n",
        "- Mudar formato da coluna número de portas.\n",
        "- Usar o KNNImputer para preencher as features vazias.\n",
        "- Atualizar o DataSet"
      ],
      "metadata": {
        "id": "IC2EGxOLdnDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ],
      "metadata": {
        "id": "7phCRYWUdoRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local = dataset.columns.get_loc('num_of_doors')\n",
        "dados_loc = list(range(18,dataset.shape[1]))\n",
        "dados_loc.insert(0, local)\n",
        "teste_knn = dataset.copy()\n",
        "modelo = teste_knn.iloc[:,dados_loc].copy()\n",
        "modelo['num_of_doors'] = modelo['num_of_doors'].replace({'two': 2,'four': 4}).tolist()\n",
        "\n",
        "# Aplicação no KNN\n",
        "impute_knn = KNNImputer(n_neighbors=6)\n",
        "novo_knn = pd.DataFrame(np.round(impute_knn.fit_transform(modelo), 2), columns=modelo.columns)\n",
        "\n",
        "# Adequar corretamente esses modelos para os casos de dados qualitativoe e quantitativos.\n",
        "\n",
        "  # Separação dos indices faltantes\n",
        "faltantes = list()\n",
        "for i in modelo:\n",
        "  a = modelo.loc[modelo[i].isnull()].index.tolist()\n",
        "  if len(a) > 0:\n",
        "    faltantes.append([i,a])\n",
        "\n",
        "\"\"\"\n",
        "Para os tipos de classificação, foi substituido pelo mais próximo.\n",
        "Para os tipos numericos, vai ser substituido pelo valor previsto.\n",
        "\"\"\"\n",
        "acumulor = list()\n",
        "for n,i in enumerate(faltantes):\n",
        "  coluna = i[0]\n",
        "  numero = i[1]\n",
        "\n",
        "  if coluna != 'price':\n",
        "    a = novo_knn[coluna][numero].tolist()\n",
        "    lista_temporaria = np.round(np.sort(modelo[coluna].unique()),2)\n",
        "    adicionar = list()\n",
        "\n",
        "    for ii in a:\n",
        "      adicionar.append(min(lista_temporaria, key=lambda x:abs(x-ii)))\n",
        "\n",
        "    posicao = modelo.columns.get_loc(coluna)\n",
        "    acumulor.append(adicionar)\n",
        "    print(adicionar)\n",
        "\n",
        "    for nn, iii in enumerate(numero):\n",
        "      modelo.iloc[iii, posicao] = adicionar[nn]\n",
        "\n",
        "  else:\n",
        "    a = novo_knn[coluna][numero].tolist()\n",
        "    print(a)\n",
        "    posicao = modelo.columns.get_loc(coluna)\n",
        "\n",
        "    for n,ii in enumerate(numero):\n",
        "      modelo.iloc[ii,posicao] = a[n]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OTbm9X9kEEP",
        "outputId": "ea1a8c7e-cc3a-4672-bff0-6514aafeb931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.0, 2.0]\n",
            "[3.24, 3.24, 3.39, 3.35]\n",
            "[3.29, 3.23, 3.27, 3.21]\n",
            "[143.0, 134.0]\n",
            "[5750.0, 5500.0]\n",
            "[16975.5, 10760.0, 10760.0, 23200.67]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passamos novamente na função tabela_resumo para verificar se está com dados faltantes e a formatação correta."
      ],
      "metadata": {
        "id": "UH_Sf26x3Ev5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.isnull().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eQNlfyK8VUs",
        "outputId": "40a2109e-4c77-49f0-8dcd-8432a3287beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tabela_resumo(modelo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "NFQuxc9X29lB",
        "outputId": "085c39e5-cda2-40b0-ebc0-90282a32f88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "               Dataset Shape: (205, 9)\n",
            "\n",
            "\n",
            "               Dataset Duplicated: 5\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Name   dtypes  Missing  Unique       max      min       mean  \\\n",
              "0       num_of_doors  float64        0       2      4.00     2.00      3.112   \n",
              "1               bore  float64        0      38      3.94     2.54      3.329   \n",
              "2             stroke  float64        0      36      4.17     2.07      3.255   \n",
              "3  compression_ratio  float64        0      32     23.00     7.00     10.143   \n",
              "4         horsepower  float64        0      59    288.00    48.00    104.590   \n",
              "5           peak_rpm  float64        0      23   6600.00  4150.00   5130.244   \n",
              "6           city_mpg    int64        0      29     49.00    13.00     25.220   \n",
              "7        highway_mpg    int64        0      30     54.00    16.00     30.751   \n",
              "8              price  float64        0     189  45400.00  5118.00  13250.386   \n",
              "\n",
              "        std    median  Most repeated  Repeated counts  First Value  \\\n",
              "0     0.996      4.00           4.00              114         2.00   \n",
              "1     0.271      3.31           3.62               23         3.47   \n",
              "2     0.314      3.29           3.40               20         2.68   \n",
              "3     3.972      9.00           9.00               46         9.00   \n",
              "4    39.665     95.00          68.00               19       111.00   \n",
              "5   479.673   5200.00        5500.00               38      5000.00   \n",
              "6     6.542     24.00          31.00               28        21.00   \n",
              "7     6.886     30.00          25.00               19        27.00   \n",
              "8  7907.814  10595.00        8921.00                2     13495.00   \n",
              "\n",
              "   Second Value  \n",
              "0          2.00  \n",
              "1          3.47  \n",
              "2          2.68  \n",
              "3          9.00  \n",
              "4        111.00  \n",
              "5       5000.00  \n",
              "6         21.00  \n",
              "7         27.00  \n",
              "8      16500.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a08542ab-ce07-4ce0-ae11-339d8e02a026\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>dtypes</th>\n",
              "      <th>Missing</th>\n",
              "      <th>Unique</th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>median</th>\n",
              "      <th>Most repeated</th>\n",
              "      <th>Repeated counts</th>\n",
              "      <th>First Value</th>\n",
              "      <th>Second Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>num_of_doors</td>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.112</td>\n",
              "      <td>0.996</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>114</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bore</td>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>3.94</td>\n",
              "      <td>2.54</td>\n",
              "      <td>3.329</td>\n",
              "      <td>0.271</td>\n",
              "      <td>3.31</td>\n",
              "      <td>3.62</td>\n",
              "      <td>23</td>\n",
              "      <td>3.47</td>\n",
              "      <td>3.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stroke</td>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>4.17</td>\n",
              "      <td>2.07</td>\n",
              "      <td>3.255</td>\n",
              "      <td>0.314</td>\n",
              "      <td>3.29</td>\n",
              "      <td>3.40</td>\n",
              "      <td>20</td>\n",
              "      <td>2.68</td>\n",
              "      <td>2.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>compression_ratio</td>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>23.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>10.143</td>\n",
              "      <td>3.972</td>\n",
              "      <td>9.00</td>\n",
              "      <td>9.00</td>\n",
              "      <td>46</td>\n",
              "      <td>9.00</td>\n",
              "      <td>9.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>horsepower</td>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "      <td>288.00</td>\n",
              "      <td>48.00</td>\n",
              "      <td>104.590</td>\n",
              "      <td>39.665</td>\n",
              "      <td>95.00</td>\n",
              "      <td>68.00</td>\n",
              "      <td>19</td>\n",
              "      <td>111.00</td>\n",
              "      <td>111.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>peak_rpm</td>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>6600.00</td>\n",
              "      <td>4150.00</td>\n",
              "      <td>5130.244</td>\n",
              "      <td>479.673</td>\n",
              "      <td>5200.00</td>\n",
              "      <td>5500.00</td>\n",
              "      <td>38</td>\n",
              "      <td>5000.00</td>\n",
              "      <td>5000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>city_mpg</td>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>49.00</td>\n",
              "      <td>13.00</td>\n",
              "      <td>25.220</td>\n",
              "      <td>6.542</td>\n",
              "      <td>24.00</td>\n",
              "      <td>31.00</td>\n",
              "      <td>28</td>\n",
              "      <td>21.00</td>\n",
              "      <td>21.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>highway_mpg</td>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>54.00</td>\n",
              "      <td>16.00</td>\n",
              "      <td>30.751</td>\n",
              "      <td>6.886</td>\n",
              "      <td>30.00</td>\n",
              "      <td>25.00</td>\n",
              "      <td>19</td>\n",
              "      <td>27.00</td>\n",
              "      <td>27.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>price</td>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>45400.00</td>\n",
              "      <td>5118.00</td>\n",
              "      <td>13250.386</td>\n",
              "      <td>7907.814</td>\n",
              "      <td>10595.00</td>\n",
              "      <td>8921.00</td>\n",
              "      <td>2</td>\n",
              "      <td>13495.00</td>\n",
              "      <td>16500.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a08542ab-ce07-4ce0-ae11-339d8e02a026')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a08542ab-ce07-4ce0-ae11-339d8e02a026 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a08542ab-ce07-4ce0-ae11-339d8e02a026');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "realizar a substituição no DataSet e novamente passar na tabela resumo para verificar se está tudo de acordo com o planejado."
      ],
      "metadata": {
        "id": "PYmB0EgI3M2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in modelo:\n",
        "  dataset[i] = modelo[i].tolist()"
      ],
      "metadata": {
        "id": "E2nVGJTi3DXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabela_resumo(dataset)"
      ],
      "metadata": {
        "id": "vE1jzvik3W2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning\n",
        "\n",
        "1. Realizar a separação do dado a ser previsto e dividir os vazios como a previsão.\n",
        "2. Utilizar o PyTorch para a criação de uma rede neural para previsão da feature normalized losses.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z_EsOeYxoNNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Separação dos dados**"
      ],
      "metadata": {
        "id": "_RzBRF2HyPTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset['normalized_losses']\n",
        "x = dataset.drop('normalized_losses',axis=1)"
      ],
      "metadata": {
        "id": "_Sbw-XHCpImy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tratando os dados para passar ao regressor.\n",
        "1. Por na formatação obj os dados qualitativos e float os qualitativos.\n",
        "2. Label encoder para os dados qualitativos"
      ],
      "metadata": {
        "id": "9TFo5_vU3tQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qual = unicos(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovwurVqN4Jom",
        "outputId": "9ddeec8d-a685-42f0-9be3-7cd96ba983eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo: symboling \n",
            "   -> [ 3  1  2  0 -1 -2]\n",
            "\n",
            "Modelo: make \n",
            "   -> ['alfa-romero' 'audi' 'bmw' 'chevrolet' 'dodge' 'honda' 'isuzu' 'jaguar'\n",
            " 'mazda' 'mercedes-benz' 'mercury' 'mitsubishi' 'nissan' 'peugot'\n",
            " 'plymouth' 'porsche' 'renault' 'saab' 'subaru' 'toyota' 'volkswagen'\n",
            " 'volvo']\n",
            "\n",
            "Modelo: fuel_type \n",
            "   -> ['gas' 'diesel']\n",
            "\n",
            "Modelo: aspiration \n",
            "   -> ['std' 'turbo']\n",
            "\n",
            "Modelo: num_of_doors \n",
            "   -> [2. 4.]\n",
            "\n",
            "Modelo: body_style \n",
            "   -> ['convertible' 'hatchback' 'sedan' 'wagon' 'hardtop']\n",
            "\n",
            "Modelo: drive_wheels \n",
            "   -> ['rwd' 'fwd' '4wd']\n",
            "\n",
            "Modelo: engine_location \n",
            "   -> ['front' 'rear']\n",
            "\n",
            "Modelo: wheel_base \n",
            "   -> [ 88.6  94.5  99.8  99.4 105.8  99.5 101.2 103.5 110.   88.4  93.7 103.3\n",
            "  95.9  86.6  96.5  94.3  96.  113.  102.   93.1  95.3  98.8 104.9 106.7\n",
            " 115.6  96.6 120.9 112.  102.7  93.   96.3  95.1  97.2 100.4  91.3  99.2\n",
            " 107.9 114.2 108.   89.5  98.4  96.1  99.1  93.3  97.   96.9  95.7 102.4\n",
            " 102.9 104.5  97.3 104.3 109.1]\n",
            "\n",
            "Modelo: length \n",
            "   -> [168.8 171.2 176.6 177.3 192.7 178.2 176.8 189.  193.8 197.  141.1 155.9\n",
            " 158.8 157.3 174.6 173.2 144.6 150.  163.4 157.1 167.5 175.4 169.1 170.7\n",
            " 172.6 199.6 191.7 159.1 166.8 169.  177.8 175.  190.9 187.5 202.6 180.3\n",
            " 208.1 199.2 178.4 173.  172.4 165.3 170.2 165.6 162.4 173.4 181.7 184.6\n",
            " 178.5 186.7 198.9 167.3 168.9 175.7 181.5 186.6 156.9 157.9 172.  173.5\n",
            " 173.6 158.7 169.7 166.3 168.7 176.2 175.6 183.5 187.8 171.7 159.3 165.7\n",
            " 180.2 183.1 188.8]\n",
            "\n",
            "Modelo: width \n",
            "   -> [64.1 65.5 66.2 66.4 66.3 71.4 67.9 64.8 66.9 70.9 60.3 63.6 63.8 64.6\n",
            " 63.9 64.  65.2 62.5 66.  61.8 69.6 70.6 64.2 65.7 66.5 66.1 70.3 71.7\n",
            " 70.5 72.  68.  64.4 65.4 68.4 68.3 65.  72.3 66.6 63.4 65.6 67.7 67.2\n",
            " 68.9 68.8]\n",
            "\n",
            "Modelo: height \n",
            "   -> [48.8 52.4 54.3 53.1 55.7 55.9 52.  53.7 56.3 53.2 50.8 50.6 59.8 50.2\n",
            " 52.6 54.5 58.3 53.3 54.1 51.  53.5 51.4 52.8 47.8 49.6 55.5 54.4 56.5\n",
            " 58.7 54.9 56.7 55.4 54.8 49.4 51.6 54.7 55.1 56.1 49.7 56.  50.5 55.2\n",
            " 52.5 53.  59.1 53.9 55.6 56.2 57.5]\n",
            "\n",
            "Modelo: engine_type \n",
            "   -> ['dohc' 'ohcv' 'ohc' 'l' 'rotor' 'ohcf' 'dohcv']\n",
            "\n",
            "Modelo: num_of_cylinders \n",
            "   -> ['four' 'six' 'five' 'three' 'twelve' 'two' 'eight']\n",
            "\n",
            "Modelo: engine_size \n",
            "   -> [130 152 109 136 131 108 164 209  61  90  98 122 156  92  79 110 111 119\n",
            " 258 326  91  70  80 140 134 183 234 308 304  97 103 120 181 151 194 203\n",
            " 132 121 146 171 161 141 173 145]\n",
            "\n",
            "Modelo: fuel_system \n",
            "   -> ['mpfi' '2bbl' 'mfi' '1bbl' 'spfi' '4bbl' 'idi' 'spdi']\n",
            "\n",
            "Modelo: bore \n",
            "   -> [3.47 2.68 3.19 3.13 3.5  3.31 3.62 2.91 3.03 2.97 3.34 3.6  2.92 3.15\n",
            " 3.43 3.63 3.54 3.08 3.24 3.39 3.35 3.76 3.58 3.46 3.8  3.78 3.17 3.59\n",
            " 2.99 3.33 3.7  3.61 3.94 3.74 2.54 3.05 3.27 3.01]\n",
            "\n",
            "Modelo: stroke \n",
            "   -> [2.68 3.47 3.4  2.8  3.19 3.39 3.03 3.11 3.23 3.46 3.9  3.41 3.07 3.58\n",
            " 4.17 2.76 3.15 3.29 3.27 3.21 3.16 3.64 3.1  3.35 3.12 3.86 3.52 2.19\n",
            " 2.9  2.07 2.36 2.64 3.08 3.5  3.54 2.87]\n",
            "\n",
            "Modelo: compression_ratio \n",
            "   -> [ 9.   10.    8.    8.5   8.3   7.    8.8   9.5   9.6   9.41  9.4   7.6\n",
            "  9.2  10.1   9.1   8.1  11.5   8.6  22.7  22.   21.5   7.5  21.9   7.8\n",
            "  8.4  21.    8.7   9.31  9.3   7.7  22.5  23.  ]\n",
            "\n",
            "Modelo: horsepower \n",
            "   -> [111. 154. 102. 115. 110. 140. 160. 101. 121. 182.  48.  70.  68.  88.\n",
            " 145.  58.  76.  60.  86. 100.  78.  90. 176. 262. 135.  84.  64. 120.\n",
            "  72. 123. 155. 184. 175. 116.  69.  55.  97. 152. 200.  95. 142. 143.\n",
            " 207. 288. 134.  73.  82.  94.  62.  56. 112.  92. 161. 156.  52.  85.\n",
            " 114. 162. 106.]\n",
            "\n",
            "Modelo: peak_rpm \n",
            "   -> [5000. 5500. 5800. 4250. 5400. 5100. 4800. 6000. 4750. 4650. 4200. 4350.\n",
            " 4500. 5200. 4150. 5600. 5900. 5750. 5250. 4900. 4400. 6600. 5300.]\n",
            "\n",
            "Modelo: city_mpg \n",
            "   -> [21 19 24 18 17 16 23 20 15 47 38 37 31 49 30 27 25 13 26 36 22 14 45 28\n",
            " 32 35 34 29 33]\n",
            "\n",
            "Modelo: highway_mpg \n",
            "   -> [27 26 30 22 25 20 29 28 53 43 41 38 24 54 42 34 33 31 19 17 23 32 39 18\n",
            " 16 37 50 36 47 46]\n",
            "Dados quantitativos : ['curb_weight', 'price']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transformador(x, qual):\n",
        "  # Importações\n",
        "  from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "  # Selecionando as variáveis qualitativas\n",
        "  indices_qual = set(range(len(x.columns)))\n",
        "\n",
        "  for i in qual:\n",
        "    atual = set([int(x.columns.get_loc(i))])\n",
        "    indices_qual = indices_qual - atual\n",
        "  indices_qualitativos = list(indices_qual)\n",
        "\n",
        "  # Label Encoder\n",
        "  novo_x = x.copy()\n",
        "  lb = LabelEncoder()\n",
        "  for i in x.iloc[:,indices_qualitativos]:\n",
        "    novo_x[i] = lb.fit_transform(x[i])\n",
        "  \n",
        "  # Padronização\n",
        "  std = StandardScaler()\n",
        "  std_x = std.fit_transform(novo_x)\n",
        "  for n,i in enumerate(novo_x):\n",
        "    novo_x[i] = std_x[:,n]\n",
        "  return novo_x"
      ],
      "metadata": {
        "id": "PICvZi4w4yJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = transformador(x, qual)"
      ],
      "metadata": {
        "id": "QU3Rz60K7bO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indice_completo = y.loc[(y.notnull())].index.tolist()\n",
        "ytr = y.iloc[indice_completo]\n",
        "xtr = x.iloc[indice_completo,:]\n",
        "indice = set(y.index.tolist())\n",
        "indice_previsor = list(indice - set(indice_completo))\n",
        "x_previsor = x.iloc[indice_previsor, :]\n"
      ],
      "metadata": {
        "id": "GjhumaZK4hgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_previsor"
      ],
      "metadata": {
        "id": "tq2eBIsR3mKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Função do pytorch**"
      ],
      "metadata": {
        "id": "fwWhn0HWySch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regressor_pytorch(xtr, xte, ytr, epocas, batch):\n",
        "  \"\"\" \n",
        "  epocas = epocas a ser treinado\n",
        "  batch = tamanho da separação do mesmo dado para um mini treinamento\n",
        "\n",
        "  Para essa função, a seguinte ordem será seguida:\n",
        "\n",
        "  1. Transformar os dados de entrada para o formato tensor\n",
        "  2. Criar a arquitetura da rede neural\n",
        "  3. Criar o Dataset E batch_loader\n",
        "  4. Criar a função erro e escolher o gradiente \n",
        "  5. Fazer os loopings \n",
        "  \"\"\"\n",
        "  # Importações\n",
        "  import torch \n",
        "  from torch import nn, optim\n",
        "  import torch.utils.data as data\n",
        "\n",
        "  # Transformaçao\n",
        "  xtr = torch.tensor(np.array(xtr), dtype=torch.float)\n",
        "  ytr = torch.tensor(np.array(ytr), dtype=torch.float).view(-1,1) # View transforma de [] para [[]]\n",
        "  xte = torch.tensor(np.array(xte), dtype=torch.float)\n",
        "\n",
        "  # Arquitetura\n",
        "  regressor = nn.Sequential(\n",
        "          nn.Linear(25, 16),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.Linear(16, 16),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.Linear(16,1)\n",
        "      )\n",
        "\n",
        "\n",
        "  #Dataset\n",
        "  dataset = data.TensorDataset(xtr, ytr)\n",
        "\n",
        "  batch_loader = data.DataLoader(dataset,\n",
        "                                 batch_size=batch,\n",
        "                                 shuffle=True)\n",
        "  \n",
        "  # Erro e Gradiente\n",
        "  criterion = nn.L1Loss()\n",
        "\n",
        "  optimizer = optim.SGD(regressor.parameters(),\n",
        "                        lr=0.001)\n",
        "  \n",
        "  # LOOPING\n",
        "\n",
        "  for epochs in range(epocas):\n",
        "    running_loss = 0.\n",
        "\n",
        "    for batch_set in batch_loader:\n",
        "      inputs, labels = batch_set\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = regressor.forward(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    error = running_loss / len(batch_loader)\n",
        "    if epochs % 100 == 0:\n",
        "      print(f'---- Epoca : {epochs} ------- Erro : {error}')\n",
        "    \n",
        "  regressor.eval()\n",
        "  saida = regressor(xte)\n",
        "  print(f'\\n\\n\\nPara os dados de treino --- Média : {ytr.mean()} --- STD : {ytr.std():.1f}')\n",
        "  print(f'Para os dados previstos --- Média : {saida.mean():.1f} --- STD : {saida.std():.1f}')\n",
        "  return saida"
      ],
      "metadata": {
        "id": "6P0VY5r6FQW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusão \n",
        "- Como os 2 primeiros objetivos alcançados, rodamos os dados na rede neural.\n",
        "- Como foi feita uma separação entre os dados faltantes e não temos como saber o erro, devido a falta de valores verdadeiros, será utilizado a média dos resultados e o desvio padrão, tanto da média dos dados reais como os dos previsoes, além também de levar em consideração o erro médio absoluto atingido ao final a execução\n",
        "- Os dados, por essas duas medidas, se mostraram muito próximos a realidade, além de apresentar um erro "
      ],
      "metadata": {
        "id": "00mj_Uz6OEhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "previsao = regressor_pytorch(xtr, x_previsor, ytr, 300, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sxk7v4mL3ZJ-",
        "outputId": "cdd6fdd8-f0c6-40c5-f11c-d7883adc7a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Epoca : 0 ------- Erro : 122.38795725504558\n",
            "---- Epoca : 100 ------- Erro : 117.64518313937717\n",
            "---- Epoca : 200 ------- Erro : 45.71936374240451\n",
            "\n",
            "\n",
            "\n",
            "Para os dados de treino --- Média : 122.0 --- STD : 35.4\n",
            "Para os dados previstos --- Média : 127.7 --- STD : 27.4\n"
          ]
        }
      ]
    }
  ]
}